{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取資料並填補nan\n",
    "train=pd.read_csv(\"data_processed/train.csv\")\n",
    "test=pd.read_csv(\"data_processed/test.csv\")\n",
    "target=pd.read_csv(\"data_processed/target.csv\")\n",
    "train=train.fillna(0)\n",
    "target=target.fillna(0)\n",
    "test=test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop([\"Unnamed: 0\"], axis=1)\n",
    "test=test.drop([\"Unnamed: 0\"], axis=1)\n",
    "target=target.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train=train.convert_objects(convert_numeric=True)\n",
    "test=test.convert_objects(convert_numeric=True)\n",
    "target=target.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將資料標準化\n",
    "train=(train-train.mean())/train.std()\n",
    "test=(test-test.mean())/test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.array(train)\n",
    "test=np.array(test)\n",
    "target=np.array(target)\n",
    "target=target.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 24        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 28\n",
      "Trainable params: 28\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6639676 samples, validate on 737742 samples\n",
      "Epoch 1/1\n",
      "6639676/6639676 [==============================] - 160s 24us/step - loss: 0.6557 - acc: 0.6237 - val_loss: 0.6753 - val_acc: 0.5965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#建立模型\n",
    "model=Sequential()\n",
    "model.add(Dense(units=800,input_dim=23,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=100,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(units=10,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.00075),metrics=['accuracy'])\n",
    "train_history=model.fit(x=train,y=target,validation_split=0.2,epochs=100,batch_size=50,verbose=1)\n",
    "\n",
    "#將歷史資訊畫出來\n",
    "def show_train_history(train_history,train,validation,name):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'],loc='upper left')\n",
    "    plt.savefig(name+'.jpg')\n",
    "    plt.clf()\n",
    "show_train_history(train_history,'acc','val_acc','acc_image')\n",
    "show_train_history(train_history,'loss','val_loss','loss_image')\n",
    "result=pd.DataFrame({'acc':train_history.history['acc'],'val_acc':train_history.history['val_acc'],'loss':train_history.history['loss'],'val_loss':train_history.history['val_loss']})\n",
    "result.to_csv(\"target.csv\", encoding='utf_8_sig')\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  target\n",
      "0              0       1\n",
      "1              1       1\n",
      "2              2       0\n",
      "3              3       0\n",
      "4              4       0\n",
      "5              5       0\n",
      "6              6       0\n",
      "7              7       1\n",
      "8              8       0\n",
      "9              9       1\n",
      "10            10       1\n",
      "11            11       1\n",
      "12            12       1\n",
      "13            13       0\n",
      "14            14       1\n",
      "15            15       1\n",
      "16            16       1\n",
      "17            17       1\n",
      "18            18       0\n",
      "19            19       1\n",
      "20            20       1\n",
      "21            21       1\n",
      "22            22       1\n",
      "23            23       1\n",
      "24            24       1\n",
      "25            25       1\n",
      "26            26       1\n",
      "27            27       1\n",
      "28            28       1\n",
      "29            29       1\n",
      "...          ...     ...\n",
      "2556760  2556760       1\n",
      "2556761  2556761       1\n",
      "2556762  2556762       1\n",
      "2556763  2556763       1\n",
      "2556764  2556764       1\n",
      "2556765  2556765       1\n",
      "2556766  2556766       1\n",
      "2556767  2556767       1\n",
      "2556768  2556768       1\n",
      "2556769  2556769       1\n",
      "2556770  2556770       1\n",
      "2556771  2556771       0\n",
      "2556772  2556772       1\n",
      "2556773  2556773       1\n",
      "2556774  2556774       0\n",
      "2556775  2556775       0\n",
      "2556776  2556776       0\n",
      "2556777  2556777       0\n",
      "2556778  2556778       1\n",
      "2556779  2556779       0\n",
      "2556780  2556780       0\n",
      "2556781  2556781       0\n",
      "2556782  2556782       0\n",
      "2556783  2556783       1\n",
      "2556784  2556784       0\n",
      "2556785  2556785       0\n",
      "2556786  2556786       1\n",
      "2556787  2556787       1\n",
      "2556788  2556788       1\n",
      "2556789  2556789       1\n",
      "\n",
      "[2556790 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#預測test.csv的資料\n",
    "get_predict=model.predict_classes(test)\n",
    "get_predict=pd.DataFrame(get_predict)\n",
    "get_predict=get_predict.reset_index()\n",
    "get_predict.columns=['id','target']\n",
    "get_predict.to_csv(\"submission.csv\", encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
